{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5b66e5-525e-44f9-a798-2c913bf3c890",
   "metadata": {},
   "source": [
    "# AI Based Chatbot to answer Linux Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e48cd-9f9a-4f30-8551-8b89f096df8b",
   "metadata": {},
   "source": [
    "### We intend to create LLM based AI Chatbot that would answer the questions about Linux\n",
    "\n",
    "It is simple LLM bot that answers the questions only on the trained dataset unlike RAG. We will train the data on the corpus of few Linux books like Linux Bible, etc. The vectorstore to store the learnings is FAISS database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada4d1c-f060-492e-abe7-253d07cb5eb6",
   "metadata": {},
   "source": [
    "### Technology Used\n",
    "1. __LLM__: meta-llama/Llama-2-7b-chat-hf [https://huggingface.co/meta-llama/Llama-2-7b-chat-hf]\n",
    "2. __VectorStore__: ___FAISS___ => FAISS (Facebook AI Similarity Search) is a library that allows developers to quickly search for embeddings of multimedia documents that are similar to each other [https://ai.meta.com/tools/faiss/]\n",
    "3. __Embeddings__: ___sentence-transformers/all-mpnet-base-v2___ [https://huggingface.co/sentence-transformers/all-mpnet-base-v2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14f491-89b7-4635-a774-ad4124301bdc",
   "metadata": {},
   "source": [
    "### Installing dependencies using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60274355-4872-4b54-a179-eedf91cb8d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.39.0)\n",
      "Requirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (3.17.4)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.0.318)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.1.2)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.21.0)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.39.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.31.0)\n",
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
      "Requirement already satisfied: faiss_cpu in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.7.4)\n",
      "Requirement already satisfied: chainlit in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.7.700)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.19.0)\n",
      "Requirement already satisfied: unstructured in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.11.6)\n",
      "Requirement already satisfied: xformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.0.23.post1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (1.4.49)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (0.0.60)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 2)) (8.2.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 3)) (12.3.101)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 4)) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 4)) (5.9.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 6)) (4.66.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (0.15.2a0+072ec57)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (1.11.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (0.1.99)\n",
      "Requirement already satisfied: aiofiles<24.0.0,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (23.2.1)\n",
      "Requirement already satisfied: asyncer<0.0.3,>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (0.0.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: fastapi<0.101,>=0.100 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (0.100.1)\n",
      "Requirement already satisfied: fastapi-socketio<0.0.11,>=0.0.10 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (0.0.10)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: httpx<0.25.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (0.24.1)\n",
      "Requirement already satisfied: lazify<0.5.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (0.4.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (1.5.8)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (2.8.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (1.0.0)\n",
      "Requirement already satisfied: python-graphql-client<0.5.0,>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (0.4.3)\n",
      "Requirement already satisfied: python-multipart<0.0.7,>=0.0.6 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (0.0.6)\n",
      "Requirement already satisfied: syncer<3.0.0,>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (2.0.3)\n",
      "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (2.0.1)\n",
      "Requirement already satisfied: uptrace<2.0.0,>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (1.22.0)\n",
      "Requirement already satisfied: uvicorn<0.24.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (0.23.2)\n",
      "Requirement already satisfied: watchfiles<0.21.0,>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from chainlit->-r requirements.txt (line 9)) (0.20.0)\n",
      "Requirement already satisfied: chardet in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (5.2.0)\n",
      "Requirement already satisfied: python-magic in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (0.4.27)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (5.0.0)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (4.12.2)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (2.9.0)\n",
      "Requirement already satisfied: python-iso639 in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (2024.1.2)\n",
      "Requirement already satisfied: langdetect in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (3.6.1)\n",
      "Requirement already satisfied: backoff in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (2.2.1)\n",
      "Requirement already satisfied: unstructured-client in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (0.6.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from unstructured->-r requirements.txt (line 11)) (1.15.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain->-r requirements.txt (line 2)) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2)) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi<0.101,>=0.100->chainlit->-r requirements.txt (line 9)) (0.27.0)\n",
      "Requirement already satisfied: python-socketio>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from fastapi-socketio<0.0.11,>=0.0.10->chainlit->-r requirements.txt (line 9)) (5.10.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<0.25.0,>=0.23.0->chainlit->-r requirements.txt (line 9)) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from httpx<0.25.0,>=0.23.0->chainlit->-r requirements.txt (line 9)) (0.17.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 2)) (2.4)\n",
      "Requirement already satisfied: websockets>=5.0 in /opt/conda/lib/python3.10/site-packages (from python-graphql-client<0.5.0,>=0.4.3->chainlit->-r requirements.txt (line 9)) (12.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (3.0.1)\n",
      "Requirement already satisfied: opentelemetry-api~=1.22 in /opt/conda/lib/python3.10/site-packages (from uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp~=1.22 in /opt/conda/lib/python3.10/site-packages (from uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation~=0.43b0 in /opt/conda/lib/python3.10/site-packages (from uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (0.43b0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.22 in /opt/conda/lib/python3.10/site-packages (from uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (1.22.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn<0.24.0,>=0.23.2->chainlit->-r requirements.txt (line 9)) (0.14.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->unstructured->-r requirements.txt (line 11)) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from langdetect->unstructured->-r requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers->-r requirements.txt (line 7)) (9.5.0)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /opt/conda/lib/python3.10/site-packages (from unstructured-client->unstructured->-r requirements.txt (line 11)) (1.0.6)\n",
      "Requirement already satisfied: marshmallow-enum>=1.5.1 in /opt/conda/lib/python3.10/site-packages (from unstructured-client->unstructured->-r requirements.txt (line 11)) (1.5.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from unstructured-client->unstructured->-r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in /opt/conda/lib/python3.10/site-packages (from unstructured-client->unstructured->-r requirements.txt (line 11)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from unstructured-client->unstructured->-r requirements.txt (line 11)) (2.8.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (6.8.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (1.22.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.22.0->opentelemetry-exporter-otlp~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (1.61.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.22.0->opentelemetry-exporter-otlp~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (1.54.3)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.22.0->opentelemetry-exporter-otlp~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.22.0->opentelemetry-exporter-otlp~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (1.22.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-proto==1.22.0->opentelemetry-exporter-otlp-proto-grpc==1.22.0->opentelemetry-exporter-otlp~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (4.21.12)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation~=0.43b0->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (68.2.2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (0.43b0)\n",
      "Requirement already satisfied: bidict>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit->-r requirements.txt (line 9)) (0.22.1)\n",
      "Requirement already satisfied: python-engineio>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit->-r requirements.txt (line 9)) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api~=1.22->uptrace<2.0.0,>=1.18.0->chainlit->-r requirements.txt (line 9)) (3.17.0)\n",
      "Requirement already satisfied: simple-websocket>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from python-engineio>=4.8.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit->-r requirements.txt (line 9)) (1.0.0)\n",
      "Requirement already satisfied: wsproto in /opt/conda/lib/python3.10/site-packages (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit->-r requirements.txt (line 9)) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -i https://test.pypi.org/simple/ bitsandbytes\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b659a8-e5c0-4198-bfba-0fd2b5b38b27",
   "metadata": {},
   "source": [
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad320cff-71a5-49a4-8fe8-a08847ab2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import huggingface_hub\n",
    "import torch\n",
    "from torch import cuda, bfloat16\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.globals import set_debug, set_verbose\n",
    "import logging\n",
    "set_debug(False)\n",
    "set_verbose(False)\n",
    "logging.getLogger('langchain').setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67fdf9f-8553-4601-b353-ab997bf1de45",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5ec990-bd43-4d99-9ccb-77c07314133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llama(model_id):\n",
    "    device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=bfloat16\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "            torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "    print(f\"Loading the model {model_id}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, pad_token_id=tokenizer.eos_token_id)\n",
    "    llama_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        return_full_text=True,\n",
    "        max_new_tokens=512,\n",
    "        #quantization_config=bnb_config,\n",
    "        temperature=0.7,\n",
    "        task=\"text-generation\",  # LLM task\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    llm = HuggingFacePipeline(pipeline=llama_pipeline)\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dba731-07c7-40eb-b46d-9927482f184d",
   "metadata": {},
   "source": [
    "### Logging in to HuggingFace repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dfc8dd9-8e20-44c7-80e8-c87f48609fa3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_hf_token():\n",
    "     os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "     print(\"------------------------------------\")\n",
    "     print(\"Huggingface login\")\n",
    "     huggingface_hub.login(os.environ[\"HF_TOKEN\"])\n",
    "     print(\"------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e33613-5636-42a5-8399-58412df8add3",
   "metadata": {},
   "source": [
    "### Loading the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49965f37-b387-43b0-9661-31e885c4eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(local_directory_path):\n",
    "    # For PDF files\n",
    "    print(f\"\\n------------------------------------\")\n",
    "    print(f\"Loading PDFs from {local_directory_path}\")\n",
    "    loader = DirectoryLoader(local_directory_path,\n",
    "                                glob='*.pdf',\n",
    "                                loader_cls=PyPDFLoader)\n",
    "    print(loader)\n",
    "    documents = loader.load()\n",
    "    print(documents)\n",
    "    print(f\"Documents Loaded\")\n",
    "    print(f\"------------------------------------\\n\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518592fb-914a-4188-86ff-37dcab04e298",
   "metadata": {},
   "source": [
    "### Processing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8c5557-153b-412e-902d-f71c5238f7a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_documents(documents):\n",
    "    print(f\"\\n------------------------------------\")\n",
    "    print(f\"Processing the documents\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                                    chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    print(f\"Documents processed\")\n",
    "    print(f\"------------------------------------\\n\")\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a3d910-f86d-41f0-a9f7-287fa5b9dcf8",
   "metadata": {},
   "source": [
    "### Setting the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce913b80-37ad-4124-9af6-cc2954e6c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_embeddings(model_name):\n",
    "     print(f\"\\n------------------------------------\")\n",
    "     print(f\"Setting the embeddings\")\n",
    "     embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "     print(f\"Embeddings set successfully\")\n",
    "     print(f\"------------------------------------\\n\")\n",
    "     return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ea0b9-214d-4a57-a6a6-18ccdbb69911",
   "metadata": {},
   "source": [
    "### Saving to FAISS Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5b070b0-ae52-437c-bea4-79e5505fd266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_vectorstore(texts, embeddings, vectorestore_path):\n",
    "     print(f\"\\n------------------------------------\")\n",
    "     print(f\"Saving the vectorestore to {vectorestore_path}\")\n",
    "     vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "     vectorstore.save_local(vectorestore_path)\n",
    "     print(f\"Vectore DB stored at {vectorestore_path}\")\n",
    "     print(f\"------------------------------------\\n\")\n",
    "     return vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9f5257-202d-4da8-a947-7d112ef43f47",
   "metadata": {},
   "source": [
    "### Setting the custom prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faf42d62-54f3-47ea-8d08-5fe9a8949385",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"Use the following information to answer the user's question.\n",
    "In case you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "def set_custom_prompt():\n",
    "    \"\"\"\n",
    "    Prompt template for QA retrieval for each vectorstore\n",
    "    \"\"\"\n",
    "    print(\"Setting the custom prompt\")\n",
    "    prompt = PromptTemplate(template=custom_prompt_template,\n",
    "                            input_variables=['context', 'question'])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f114cf-8bb7-4f37-b541-4a55be367da4",
   "metadata": {},
   "source": [
    "### Retrieval QA Chain function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3517f14-be57-4dcc-860d-cec5ba339da4",
   "metadata": {},
   "source": [
    "The RetrievalQAChain is a chain that combines a Retriever and a QA chain (described above). It is used to retrieve documents from a Retriever and then use a QA chain to answer a question based on the retrieved documents. [Read this for more info on RetrievalQA](https://js.langchain.com/docs/modules/chains/popular/vector_db_qa_legacy#:~:text=The%20RetrievalQAChain%20is%20a%20chain,based%20on%20the%20retrieved%20documents.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ece2e36-3349-4978-a26c-cf33e35b8e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_qa_chain(llm, vectorstore):\n",
    "     chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                         chain_type='stuff',\n",
    "                                         retriever=vectorstore.as_retriever(search_kwargs={'k': 2}), \n",
    "                                         return_source_documents=True,\n",
    "                                         chain_type_kwargs={'prompt': set_custom_prompt()},\n",
    "                                         verbose=False\n",
    "                                         )\n",
    "     return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f26d0a-a7ee-4b2a-8925-ba54fe0cf488",
   "metadata": {},
   "source": [
    "### Chatbot Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4a5f23e-a610-4641-b917-22daf5c33cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(llm, vectorstore):\n",
    "    chain = retrieval_qa_chain(llm, vectorstore)\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Thanks!\")\n",
    "            break\n",
    "        result = chain({\"query\": user_input})\n",
    "\n",
    "        response = result[\"result\"]\n",
    "        \n",
    "        print(\"Chatbot: \", response)\n",
    "        print(\"--------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71222f58-9a6a-4ca4-a510-61c3894eeaf2",
   "metadata": {},
   "source": [
    "### Sample testing. Having the debugger output on for understanding the flow of responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9fa2c1b-2831-4f49-ad2b-ede04056ea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "Huggingface login\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/sagemaker-user/.cache/huggingface/token\n",
      "Login successful\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Loading PDFs from /home/sagemaker-user/content/corpus\n",
      "<langchain.document_loaders.directory.DirectoryLoader object at 0x7f02e2b4df00>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents processed\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Setting the embeddings\n",
      "Embeddings set successfully\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Saving the vectorestore to /home/sagemaker-user/content/vectorstore/\n",
      "Vectore DB stored at /home/sagemaker-user/content/vectorstore/\n",
      "------------------------------------\n",
      "\n",
      "Loading the model meta-llama/Llama-2-7b-chat-hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ca46f4f90445ab967a9b290f79bcef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the custom prompt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is linux\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is linux\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is linux\",\n",
      "  \"context\": \"other hand, was developed in a different context. Linux is a PC version of the Unix operating system that has been used for decades on mainframes and minicomputers and is currently the system of choice for network servers and workstations. Linux brings the \\nspeed, efficiency, scalability, and flexibility of Unix to your PC, taking advantage of all the \\ncapabilities that PCs can now provide.\\nTechnically, Linux consists of the operating system program, referred to as the kernel,\\n\\nLinux ������\\n \\n������������������\\n \\n������������\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:HuggingFacePipeline] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following information to answer the user's question.\\nIn case you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nContext: other hand, was developed in a different context. Linux is a PC version of the Unix operating system that has been used for decades on mainframes and minicomputers and is currently the system of choice for network servers and workstations. Linux brings the \\nspeed, efficiency, scalability, and flexibility of Unix to your PC, taking advantage of all the \\ncapabilities that PCs can now provide.\\nTechnically, Linux consists of the operating system program, referred to as the kernel,\\n\\nLinux ������\\n \\n������������������\\n \\n������������\\nQuestion: What is linux\\n\\nOnly return the helpful answer below and nothing else.\\nHelpful answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:HuggingFacePipeline] [17.03s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Linux is an open-source operating system that is based on the Unix operating system and is designed to be highly scalable, flexible, and efficient. It is commonly used on servers and workstations, but can also be used on personal computers.\",\n",
      "        \"generation_info\": null\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] [17.03s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Linux is an open-source operating system that is based on the Unix operating system and is designed to be highly scalable, flexible, and efficient. It is commonly used on servers and workstations, but can also be used on personal computers.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] [17.03s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"Linux is an open-source operating system that is based on the Unix operating system and is designed to be highly scalable, flexible, and efficient. It is commonly used on servers and workstations, but can also be used on personal computers.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA] [17.07s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "Chatbot:  Linux is an open-source operating system that is based on the Unix operating system and is designed to be highly scalable, flexible, and efficient. It is commonly used on servers and workstations, but can also be used on personal computers.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"bye\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"bye\",\n",
      "  \"context\": \"114 Part II: The Linux Shell and File Structure\\nAs with .login , you can add your own shell commands to the .logout  file. Using the Vi \\neditor, you can change the farewell message or add other operations. In the next example, the user has a \\nclear  and an echo  command in the .logout  file. When the user logs out, the \\nclear  command will clear the screen, and echo  will display the message “Good-bye for \\nnow”.\\n.logout\\nclear\\necho \\\"Good-bye for now\\\"\\n\\nexit(0) A;[Enter]}[Esc] exit(0);\\n  }/\\ndas76205_Ch05_122-155.indd   128das76205_Ch05_122-155.indd   128 12/13/11   10:44 AM12/13/11   10:44 AM\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:HuggingFacePipeline] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following information to answer the user's question.\\nIn case you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nContext: 114 Part II: The Linux Shell and File Structure\\nAs with .login , you can add your own shell commands to the .logout  file. Using the Vi \\neditor, you can change the farewell message or add other operations. In the next example, the user has a \\nclear  and an echo  command in the .logout  file. When the user logs out, the \\nclear  command will clear the screen, and echo  will display the message “Good-bye for \\nnow”.\\n.logout\\nclear\\necho \\\"Good-bye for now\\\"\\n\\nexit(0) A;[Enter]}[Esc] exit(0);\\n  }/\\ndas76205_Ch05_122-155.indd   128das76205_Ch05_122-155.indd   128 12/13/11   10:44 AM12/13/11   10:44 AM\\nQuestion: bye\\n\\nOnly return the helpful answer below and nothing else.\\nHelpful answer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:HuggingFacePipeline] [6.14s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The command to logout in Linux is \\\"exit\\\".\",\n",
      "        \"generation_info\": null\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] [6.14s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The command to logout in Linux is \\\"exit\\\".\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] [6.14s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"The command to logout in Linux is \\\"exit\\\".\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA] [6.17s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "Chatbot:  The command to logout in Linux is \"exit\".\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Thanks!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    set_hf_token()\n",
    "    documents = load_documents(\"/home/sagemaker-user/content/corpus\")\n",
    "    texts = process_documents(documents)\n",
    "    embeddings = set_embeddings('sentence-transformers/all-mpnet-base-v2')\n",
    "    vectorstore = save_to_vectorstore(texts, embeddings, \"/home/sagemaker-user/content/vectorstore/\")\n",
    "    chatbot(load_llama(\"meta-llama/Llama-2-7b-chat-hf\"), vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd94859-b105-4881-96fd-da14eb5927ef",
   "metadata": {},
   "source": [
    "## Final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86c16667-c390-4640-8853-41e4f073000b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model meta-llama/Llama-2-7b-chat-hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d853ce2e014359993dc5106a1f4d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the custom prompt\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is linux\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  Linux is an open-source operating system that is based on the Unix operating system and is designed to be fast, efficient, scalable, and flexible. It is commonly used on servers and workstations, and is known for its stability and security.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is difference between sudo -i and sudo su -?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  sudo -i and sudo su - are both used to switch to a different user, but they have slightly different behaviors:\n",
      "\n",
      "* sudo -i runs the command as the specified user, but does not prompt for a password. Instead, it uses the user's login credentials from the session.\n",
      "* sudo su -, on the other hand, runs the command as the specified user and prompts for the user's password before executing the command.\n",
      "\n",
      "So, the main difference between the two is that sudo -i does not require a password, while sudo su - does.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is devops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  DevOps is defined as a set of principles and practices that bring both developers and operations teams together from the start of a software system development to its end-user delivery, with the goal of faster, quicker, and more efficient delivery of software systems to end customers, while reducing time to market and gaining competitive advantage.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What should be career path for devops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  The author suggests that the best career path for a DevOps engineer is to be involved in the entire SDLC (Software Development Life Cycle), solving communication problems and automating tasks to reduce human intervention. They also mention that it's important to keep up to date with the latest tools and technologies in the field.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  How to start learning linux?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  If you know absolutely nothing about Unix, we recommend you read a basic guide (introductory chapters in the O’Reilly books Learning Red Hat Enterprise Linux and Fedora, by Bill McCarty, and Running Linux, mentioned previously) to get started. This will give you a good understanding of the common utilities run from the shell prompt and how to use them.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Suggest linux learning path for beginner\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  If you are a beginner, I would suggest starting with one of the distributions listed in the text, such as KNOPPIX, Ubuntu, or Damn Small Linux. These distributions are designed to be easy to use and provide a gentle introduction to Linux. Additionally, you can try out the live CDs from the media that comes with this book to get a feel for different distributions and see which one you like best.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  list 20 important commands for linux\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  \n",
      "Here are 20 important commands in Linux:\n",
      "\n",
      "1. `cd` - change directory\n",
      "2. `ls` - list files and directories\n",
      "3. `mkdir` - make a new directory\n",
      "4. `rm` - remove a file or directory\n",
      "5. `cp` - copy a file\n",
      "6. `mv` - move or rename a file\n",
      "7. `pwd` - print the current working directory\n",
      "8. `man` - display manual pages\n",
      "9. `chmod` - change file permissions\n",
      "10. `chown` - change file ownership\n",
      "11. `find` - search for files\n",
      "12. `grep` - search for a pattern in a file\n",
      "13. `sort` - sort files\n",
      "14. `uniq` - display only unique lines in a file\n",
      "15. `cat` - concatenate and display files\n",
      "16. `nano` - a simple text editor\n",
      "17. `echo` - output text to a file\n",
      "18. `sudo` - execute a command with superuser privileges\n",
      "19. `tar` - create an archive of files\n",
      "20. `gzip` - compress a file\n",
      "\n",
      "These are just a few of the many commands available in Linux, but they are some of the most commonly used and useful ones to know.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is ci cd?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  CI/CD is an umbrella term that encompasses both Continuous Integration (CI) and Continuous Delivery (CD). It refers to the practice of automating the build, test, and deployment of software, with the goal of delivering high-quality software faster and more reliably. CI/CD involves integrating code changes, running automated tests, and deploying software to production in a repeatable and efficient manner.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  list tools for CI/CD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  There are several tools available for CI/CD, including:\n",
      "\n",
      "1. Jenkins\n",
      "2. Travis CI\n",
      "3. CircleCI\n",
      "4. Codeship\n",
      "5. GoCD\n",
      "6. TeamCity\n",
      "7. CruiseControl\n",
      "8. GitLab CI/CD\n",
      "9. AWS CodePipeline\n",
      "10. Azure DevOps\n",
      "\n",
      "Please note that this is not an exhaustive list and there are many other tools available.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is travis ci?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot:  Travis CI is one of the second-generation CI/CD tools mentioned in the passage. It is a cloud-based service that automates the build, test, and deployment process for software projects. Travis CI is known for its simplicity and ease of use, and it is often used for small to medium-sized projects.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Thanks!\n"
     ]
    }
   ],
   "source": [
    "chatbot(load_llama(\"meta-llama/Llama-2-7b-chat-hf\"), vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396f395-9330-456d-a693-8b3c9b1f21fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
